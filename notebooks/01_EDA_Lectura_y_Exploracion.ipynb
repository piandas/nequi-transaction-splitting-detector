{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "527c0904",
   "metadata": {},
   "source": [
    "# An√°lisis Exploratorio de Datos (EDA) - Detector de Divisi√≥n de Transacciones\n",
    "\n",
    "## Objetivo\n",
    "Familiarizarse con los datos de transacciones y entender su estructura:\n",
    "- Shape, tipos de datos, valores nulos, valores at√≠picos\n",
    "- Distribuciones de montos y tipos de transacciones\n",
    "- Identificaci√≥n de patrones iniciales\n",
    "\n",
    "## Dataset\n",
    "- **Archivos**: `sample_data_0006_part_00.parquet` y `sample_data_0007_part_00.parquet`\n",
    "- **Ubicaci√≥n**: `../data/`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7d557794",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Librer√≠as importadas correctamente\n"
     ]
    }
   ],
   "source": [
    "# Importar librer√≠as necesarias\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "\n",
    "# Configuraci√≥n para visualizaciones\n",
    "plt.style.use('default')\n",
    "sns.set_palette(\"husl\")\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Configuraci√≥n de pandas\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', 1000)\n",
    "\n",
    "print(\"‚úÖ Librer√≠as importadas correctamente\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f32357e",
   "metadata": {},
   "source": [
    "## 1. Carga de Datos\n",
    "\n",
    "Vamos a cargar los dos archivos parquet y verificar si tienen la misma estructura para poder unirlos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "46ec3863",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÅ Cargando archivos...\n",
      "‚úÖ Archivo 1 cargado: sample_data_0006_part_00.parquet\n",
      "   Shape: (10758418, 8)\n",
      "‚úÖ Archivo 2 cargado: sample_data_0007_part_00.parquet\n",
      "   Shape: (10758500, 8)\n"
     ]
    }
   ],
   "source": [
    "# Definir rutas de los archivos\n",
    "data_path = Path(\"../data/\")\n",
    "file1 = data_path / \"sample_data_0006_part_00.parquet\"\n",
    "file2 = data_path / \"sample_data_0007_part_00.parquet\"\n",
    "\n",
    "# Cargar cada archivo por separado para explorar\n",
    "print(\"üìÅ Cargando archivos...\")\n",
    "df1 = pd.read_parquet(file1)\n",
    "df2 = pd.read_parquet(file2)\n",
    "\n",
    "print(f\"‚úÖ Archivo 1 cargado: {file1.name}\")\n",
    "print(f\"   Shape: {df1.shape}\")\n",
    "print(f\"‚úÖ Archivo 2 cargado: {file2.name}\")\n",
    "print(f\"   Shape: {df2.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "41c66cfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Verificando estructura de los archivos...\n",
      "\n",
      "üìã COLUMNAS ARCHIVO 1:\n",
      "Columnas: ['merchant_id', '_id', 'subsidiary', 'transaction_date', 'account_number', 'user_id', 'transaction_amount', 'transaction_type']\n",
      "\n",
      "üìã COLUMNAS ARCHIVO 2:\n",
      "Columnas: ['merchant_id', '_id', 'subsidiary', 'transaction_date', 'account_number', 'user_id', 'transaction_amount', 'transaction_type']\n",
      "\n",
      "¬øLas columnas son iguales? True\n",
      "‚úÖ Los archivos tienen la misma estructura, se pueden unir\n"
     ]
    }
   ],
   "source": [
    "# Verificar estructura de ambos archivos\n",
    "print(\"üîç Verificando estructura de los archivos...\\n\")\n",
    "\n",
    "print(\"üìã COLUMNAS ARCHIVO 1:\")\n",
    "print(f\"Columnas: {list(df1.columns)}\\n\")\n",
    "\n",
    "print(\"üìã COLUMNAS ARCHIVO 2:\")\n",
    "print(f\"Columnas: {list(df2.columns)}\\n\")\n",
    "\n",
    "# Verificar si las columnas son iguales\n",
    "columnas_iguales = list(df1.columns) == list(df2.columns)\n",
    "print(f\"¬øLas columnas son iguales? {columnas_iguales}\")\n",
    "\n",
    "if columnas_iguales:\n",
    "    print(\"‚úÖ Los archivos tienen la misma estructura, se pueden unir\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Los archivos tienen diferente estructura\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f464ddd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîó Uniendo los datasets...\n",
      "‚úÖ Dataset unificado creado\n",
      "   Shape final: (21516918, 8)\n",
      "   Registros archivo 1: 10758418\n",
      "   Registros archivo 2: 10758500\n",
      "   Total registros: 21516918\n"
     ]
    }
   ],
   "source": [
    "# Unir los datasets\n",
    "if columnas_iguales:\n",
    "    print(\"üîó Uniendo los datasets...\")\n",
    "    df = pd.concat([df1, df2], ignore_index=True)\n",
    "    print(f\"‚úÖ Dataset unificado creado\")\n",
    "    print(f\"   Shape final: {df.shape}\")\n",
    "    print(f\"   Registros archivo 1: {len(df1)}\")\n",
    "    print(f\"   Registros archivo 2: {len(df2)}\")\n",
    "    print(f\"   Total registros: {len(df)}\")\n",
    "    \n",
    "    # Liberar memoria de los dataframes individuales\n",
    "    del df1, df2\n",
    "else:\n",
    "    print(\"‚ùå No se pueden unir los archivos debido a diferencias en estructura\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
