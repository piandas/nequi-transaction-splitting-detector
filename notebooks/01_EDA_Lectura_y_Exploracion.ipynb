{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "527c0904",
   "metadata": {},
   "source": [
    "# An√°lisis Exploratorio de Datos (EDA) - Limpieza y normalizacion\n",
    "\n",
    "## Objetivo\n",
    "Familiarizarse con los datos de transacciones y entender su estructura:\n",
    "- Shape, tipos de datos, valores nulos, valores at√≠picos\n",
    "- Distribuciones de montos y tipos de transacciones\n",
    "- Identificaci√≥n de patrones iniciales\n",
    "- Limpiar las columnas y organziar el df\n",
    "\n",
    "## Dataset\n",
    "- **Archivos**: `sample_data_0006_part_00.parquet` y `sample_data_0007_part_00.parquet`\n",
    "- **Ubicaci√≥n**: `../data/`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "7d557794",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Librer√≠as importadas correctamente\n"
     ]
    }
   ],
   "source": [
    "# Importar librer√≠as necesarias\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "import re\n",
    "from pathlib import Path\n",
    "\n",
    "# Configuraci√≥n para visualizaciones\n",
    "plt.style.use('default')\n",
    "sns.set_palette(\"husl\")\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Configuraci√≥n de pandas\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', 1000)\n",
    "\n",
    "print(\"‚úÖ Librer√≠as importadas correctamente\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f32357e",
   "metadata": {},
   "source": [
    "## 1. Carga de Datos\n",
    "\n",
    "Vamos a cargar los dos archivos parquet y verificar si tienen la misma estructura para poder unirlos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "46ec3863",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÅ Cargando archivos...\n",
      "‚úÖ Archivo 1 cargado: sample_data_0006_part_00.parquet\n",
      "   Shape: (10758418, 8)\n",
      "‚úÖ Archivo 2 cargado: sample_data_0007_part_00.parquet\n",
      "   Shape: (10758500, 8)\n"
     ]
    }
   ],
   "source": [
    "# Definir rutas de los archivos\n",
    "data_path = Path(\"../data/\")\n",
    "file1 = data_path / \"sample_data_0006_part_00.parquet\"\n",
    "file2 = data_path / \"sample_data_0007_part_00.parquet\"\n",
    "\n",
    "# Cargar cada archivo por separado para explorar\n",
    "print(\"üìÅ Cargando archivos...\")\n",
    "df1 = pd.read_parquet(file1)\n",
    "df2 = pd.read_parquet(file2)\n",
    "\n",
    "print(f\"‚úÖ Archivo 1 cargado: {file1.name}\")\n",
    "print(f\"   Shape: {df1.shape}\")\n",
    "print(f\"‚úÖ Archivo 2 cargado: {file2.name}\")\n",
    "print(f\"   Shape: {df2.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "41c66cfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Verificando estructura de los archivos...\n",
      "\n",
      "üìã COLUMNAS ARCHIVO 1:\n",
      "Columnas: ['merchant_id', '_id', 'subsidiary', 'transaction_date', 'account_number', 'user_id', 'transaction_amount', 'transaction_type']\n",
      "\n",
      "üìã COLUMNAS ARCHIVO 2:\n",
      "Columnas: ['merchant_id', '_id', 'subsidiary', 'transaction_date', 'account_number', 'user_id', 'transaction_amount', 'transaction_type']\n",
      "\n",
      "¬øLas columnas son iguales? True\n",
      "‚úÖ Los archivos tienen la misma estructura, se pueden unir\n"
     ]
    }
   ],
   "source": [
    "# Verificar estructura de ambos archivos\n",
    "print(\"üîç Verificando estructura de los archivos...\\n\")\n",
    "\n",
    "print(\"üìã COLUMNAS ARCHIVO 1:\")\n",
    "print(f\"Columnas: {list(df1.columns)}\\n\")\n",
    "\n",
    "print(\"üìã COLUMNAS ARCHIVO 2:\")\n",
    "print(f\"Columnas: {list(df2.columns)}\\n\")\n",
    "\n",
    "# Verificar si las columnas son iguales\n",
    "columnas_iguales = list(df1.columns) == list(df2.columns)\n",
    "print(f\"¬øLas columnas son iguales? {columnas_iguales}\")\n",
    "\n",
    "if columnas_iguales:\n",
    "    print(\"‚úÖ Los archivos tienen la misma estructura, se pueden unir\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Los archivos tienen diferente estructura\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f464ddd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîó Uniendo los datasets...\n",
      "‚úÖ Dataset unificado creado\n",
      "   Shape final: (21516918, 8)\n",
      "   Registros archivo 1: 10758418\n",
      "   Registros archivo 2: 10758500\n",
      "   Total registros: 21516918\n"
     ]
    }
   ],
   "source": [
    "# Unir los datasets\n",
    "if columnas_iguales:\n",
    "    print(\"üîó Uniendo los datasets...\")\n",
    "    df = pd.concat([df1, df2], ignore_index=True)\n",
    "    print(f\"‚úÖ Dataset unificado creado\")\n",
    "    print(f\"   Shape final: {df.shape}\")\n",
    "    print(f\"   Registros archivo 1: {len(df1)}\")\n",
    "    print(f\"   Registros archivo 2: {len(df2)}\")\n",
    "    print(f\"   Total registros: {len(df)}\")\n",
    "    \n",
    "    # Liberar memoria de los dataframes individuales\n",
    "    del df1, df2\n",
    "else:\n",
    "    print(\"‚ùå No se pueden unir los archivos debido a diferencias en estructura\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "683dad75",
   "metadata": {},
   "source": [
    "## 2. Analisis y preprocesamiento del dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "123a122a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä INFORMACI√ìN GENERAL DEL DATASET\n",
      "============================================================\n",
      "üíæ Memoria utilizada: 12234.13 MB\n",
      "\n",
      "üìã TIPOS DE DATOS:\n",
      "----------------------------------------\n",
      "  object: 7 columnas\n",
      "  datetime64[ns]: 1 columnas\n",
      "\n",
      "üìù NOMBRES DE LAS COLUMNAS:\n",
      "----------------------------------------\n",
      "   1. merchant_id (object)\n",
      "   2. _id (object)\n",
      "   3. subsidiary (object)\n",
      "   4. transaction_date (datetime64[ns])\n",
      "   5. account_number (object)\n",
      "   6. user_id (object)\n",
      "   7. transaction_amount (object)\n",
      "   8. transaction_type (object)\n",
      "\n",
      "PRIMERAS 3 FILAS:\n",
      "----------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>merchant_id</th>\n",
       "      <th>_id</th>\n",
       "      <th>subsidiary</th>\n",
       "      <th>transaction_date</th>\n",
       "      <th>account_number</th>\n",
       "      <th>user_id</th>\n",
       "      <th>transaction_amount</th>\n",
       "      <th>transaction_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>075d178871d8d48502bf1f54887e52fe</td>\n",
       "      <td>aa8dacff663072244d0a8ab6bbe36b93</td>\n",
       "      <td>824b2af470cbe6a65b15650e03b740fc</td>\n",
       "      <td>2021-09-12 18:32:03</td>\n",
       "      <td>648e257c9d74909a1f61c54b93a9e1b3</td>\n",
       "      <td>ba42d192a145583ba8e7bf04875f837f</td>\n",
       "      <td>178.33365037</td>\n",
       "      <td>CREDITO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>075d178871d8d48502bf1f54887e52fe</td>\n",
       "      <td>a53bb81bd0bba2ae2535bda7ea5a550c</td>\n",
       "      <td>2d8d34be7509a6b1262336d036fdb324</td>\n",
       "      <td>2021-09-12 18:31:58</td>\n",
       "      <td>c0b62f9046c83ea5543ea46a497a4d6e</td>\n",
       "      <td>5cfff960ea6d732c1ba3e63d24f3be52</td>\n",
       "      <td>35.66673007</td>\n",
       "      <td>CREDITO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>075d178871d8d48502bf1f54887e52fe</td>\n",
       "      <td>79f893ea65c06fe2933f3847c88c272f</td>\n",
       "      <td>5eeb18254850b21af0a6bb2697913cd3</td>\n",
       "      <td>2021-09-12 18:31:56</td>\n",
       "      <td>872d10143fc0ac7d5de467806f6bef81</td>\n",
       "      <td>c97e63a92c82c7217b333635d75928ed</td>\n",
       "      <td>142.66692029</td>\n",
       "      <td>CREDITO</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        merchant_id                               _id                        subsidiary    transaction_date                    account_number                           user_id transaction_amount transaction_type\n",
       "0  075d178871d8d48502bf1f54887e52fe  aa8dacff663072244d0a8ab6bbe36b93  824b2af470cbe6a65b15650e03b740fc 2021-09-12 18:32:03  648e257c9d74909a1f61c54b93a9e1b3  ba42d192a145583ba8e7bf04875f837f       178.33365037          CREDITO\n",
       "1  075d178871d8d48502bf1f54887e52fe  a53bb81bd0bba2ae2535bda7ea5a550c  2d8d34be7509a6b1262336d036fdb324 2021-09-12 18:31:58  c0b62f9046c83ea5543ea46a497a4d6e  5cfff960ea6d732c1ba3e63d24f3be52        35.66673007          CREDITO\n",
       "2  075d178871d8d48502bf1f54887e52fe  79f893ea65c06fe2933f3847c88c272f  5eeb18254850b21af0a6bb2697913cd3 2021-09-12 18:31:56  872d10143fc0ac7d5de467806f6bef81  c97e63a92c82c7217b333635d75928ed       142.66692029          CREDITO"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "√öLTIMAS 3 FILAS:\n",
      "----------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>merchant_id</th>\n",
       "      <th>_id</th>\n",
       "      <th>subsidiary</th>\n",
       "      <th>transaction_date</th>\n",
       "      <th>account_number</th>\n",
       "      <th>user_id</th>\n",
       "      <th>transaction_amount</th>\n",
       "      <th>transaction_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>21516915</th>\n",
       "      <td>838a8fa992a4aa2fb5a0cf8b15b63755</td>\n",
       "      <td>f19c70c14bae6f6c8d53c2a85f5f59f6</td>\n",
       "      <td>55fb0b01915693a7d5de686f9f4b1cb6</td>\n",
       "      <td>2021-11-30 11:01:07</td>\n",
       "      <td>90865ae9ab4d82a1feec13eee9a4a303</td>\n",
       "      <td>356058d6c9548879be6ef65a9733ea44</td>\n",
       "      <td>594.44550123</td>\n",
       "      <td>CREDITO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21516916</th>\n",
       "      <td>838a8fa992a4aa2fb5a0cf8b15b63755</td>\n",
       "      <td>8d43b7b55023ccae39735707a811f38f</td>\n",
       "      <td>55fb0b01915693a7d5de686f9f4b1cb6</td>\n",
       "      <td>2021-11-30 11:02:05</td>\n",
       "      <td>90865ae9ab4d82a1feec13eee9a4a303</td>\n",
       "      <td>356058d6c9548879be6ef65a9733ea44</td>\n",
       "      <td>172.38919535</td>\n",
       "      <td>CREDITO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21516917</th>\n",
       "      <td>838a8fa992a4aa2fb5a0cf8b15b63755</td>\n",
       "      <td>b15c20c071ab0df8fa15c71e4dd35e7d</td>\n",
       "      <td>189977b64fded8e9a37df9fc749fad5c</td>\n",
       "      <td>2021-11-29 14:07:30</td>\n",
       "      <td>528173dc0da13e78938c9e58c5cb3673</td>\n",
       "      <td>9b4a7ac86ed81ad330366e766c739808</td>\n",
       "      <td>47.55564009</td>\n",
       "      <td>CREDITO</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               merchant_id                               _id                        subsidiary    transaction_date                    account_number                           user_id transaction_amount transaction_type\n",
       "21516915  838a8fa992a4aa2fb5a0cf8b15b63755  f19c70c14bae6f6c8d53c2a85f5f59f6  55fb0b01915693a7d5de686f9f4b1cb6 2021-11-30 11:01:07  90865ae9ab4d82a1feec13eee9a4a303  356058d6c9548879be6ef65a9733ea44       594.44550123          CREDITO\n",
       "21516916  838a8fa992a4aa2fb5a0cf8b15b63755  8d43b7b55023ccae39735707a811f38f  55fb0b01915693a7d5de686f9f4b1cb6 2021-11-30 11:02:05  90865ae9ab4d82a1feec13eee9a4a303  356058d6c9548879be6ef65a9733ea44       172.38919535          CREDITO\n",
       "21516917  838a8fa992a4aa2fb5a0cf8b15b63755  b15c20c071ab0df8fa15c71e4dd35e7d  189977b64fded8e9a37df9fc749fad5c 2021-11-29 14:07:30  528173dc0da13e78938c9e58c5cb3673  9b4a7ac86ed81ad330366e766c739808        47.55564009          CREDITO"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Vista r√°pida e informaci√≥n general del dataset\n",
    "print(\"üìä INFORMACI√ìN GENERAL DEL DATASET\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"üíæ Memoria utilizada: {df.memory_usage(deep=True).sum() / 1024**2:.2f} MB\")\n",
    "\n",
    "print(\"\\nüìã TIPOS DE DATOS:\")\n",
    "print(\"-\" * 40)\n",
    "tipo_counts = df.dtypes.value_counts()\n",
    "for tipo, count in tipo_counts.items():\n",
    "    print(f\"  {tipo}: {count} columnas\")\n",
    "\n",
    "print(f\"\\nüìù NOMBRES DE LAS COLUMNAS:\")\n",
    "print(\"-\" * 40)\n",
    "for i, col in enumerate(df.columns, 1):\n",
    "    print(f\"  {i:2d}. {col} ({df[col].dtype})\")\n",
    "\n",
    "print(f\"\\nPRIMERAS 3 FILAS:\")\n",
    "print(\"-\" * 40)\n",
    "display(df.head(3))\n",
    "\n",
    "print(f\"\\n√öLTIMAS 3 FILAS:\")\n",
    "print(\"-\" * 40)\n",
    "display(df.tail(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0d920c85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìà ESTAD√çSTICAS DESCRIPTIVAS B√ÅSICAS\n",
      "============================================================\n",
      "üìä Columnas num√©ricas encontradas: 0\n",
      "‚ö†Ô∏è No se encontraron columnas num√©ricas\n",
      "\n",
      "üìù Columnas de texto/categ√≥ricas encontradas: 7\n",
      "Columnas: ['merchant_id', '_id', 'subsidiary', 'account_number', 'user_id', 'transaction_amount', 'transaction_type']\n",
      "\n",
      "  üìä merchant_id:\n",
      "    Valores √∫nicos: 3\n",
      "    Tipo: object\n",
      "    Valores: ['075d178871d8d48502bf1f54887e52fe', '817d18cd3c31e40e9bff0566baae7758', '838a8fa992a4aa2fb5a0cf8b15b63755']\n",
      "\n",
      "  üìä _id:\n",
      "    Valores √∫nicos: 21,516,901\n",
      "    Tipo: object\n",
      "    Primeros 5 valores: ['000000c00a3d728b6b5c1580b4816959', '000002ea806e97f97a6a3d5acd2855b2', '000003f2f33e6a45ce7483113c709aa1', '000004b9c3cb1548d4f9771458dc5582', '0000059697b8090d5079c6f3e475f68b']\n",
      "\n",
      "  üìä subsidiary:\n",
      "    Valores √∫nicos: 16,833\n",
      "    Tipo: object\n",
      "    Primeros 5 valores: ['00015fd77a0f4d869bea31bb7244e375', '000b48cd239b8411eec69c69963cb5dd', '000ed83916ade2efe9c7ed9c81f6daa5', '0012d2042453597ebcf06140b0e4ec3f', '00130d1dfa59170a208840ea4004f423']\n",
      "\n",
      "  üìä account_number:\n",
      "    Valores √∫nicos: 3,099,711\n",
      "    Tipo: object\n",
      "    Primeros 5 valores: ['000009a84c209a6a3a97aa0d8d3c5241', '00000f81a1d5583a06a5cb7f4a1cbc0e', '000011b29a455d40b5aea0cfca1aa7f6', '000014fadab387e333d42770d5850019', '00001500d5a76e12b28c233bf1f8718b']\n",
      "\n",
      "  üìä user_id:\n",
      "    Valores √∫nicos: 3,087,217\n",
      "    Tipo: object\n",
      "    Primeros 5 valores: ['00000158a82e34eb0848d767d09f811d', '000002373d5835d0e53b78722424076f', '000004f4a6f3ac93f454a5dc04b2a252', '00000c80915f64c9bcbf1e85a2e5f3ec', '00000e01abb58a22cbb3cab74c316df7']\n",
      "\n",
      "  üìä transaction_amount:\n",
      "    Valores √∫nicos: 28,260\n",
      "    Tipo: object\n",
      "    Primeros 5 valores: [Decimal('5.94445501'), Decimal('5.94564390'), Decimal('5.94683279'), Decimal('5.94802168'), Decimal('5.94921057')]\n",
      "\n",
      "  üìä transaction_type:\n",
      "    Valores √∫nicos: 2\n",
      "    Tipo: object\n",
      "    Valores: ['CREDITO', 'DEBITO']\n"
     ]
    }
   ],
   "source": [
    "# Estad√≠sticas descriptivas b√°sicas\n",
    "print(\"üìà ESTAD√çSTICAS DESCRIPTIVAS B√ÅSICAS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Columnas categ√≥ricas/texto\n",
    "text_cols = df.select_dtypes(include=['object', 'string']).columns\n",
    "print(f\"\\nüìù Columnas de texto/categ√≥ricas encontradas: {len(text_cols)}\")\n",
    "if len(text_cols) > 0:\n",
    "    print(f\"Columnas: {list(text_cols)}\")\n",
    "    for col in text_cols:\n",
    "        unique_count = df[col].nunique()\n",
    "        print(f\"\\n  üìä {col}:\")\n",
    "        print(f\"    Valores √∫nicos: {unique_count:,}\")\n",
    "        print(f\"    Tipo: {df[col].dtype}\")\n",
    "        if unique_count <= 20:\n",
    "            print(f\"    Valores: {sorted(df[col].unique())}\")\n",
    "        else:\n",
    "            print(f\"    Primeros 5 valores: {sorted(df[col].unique())[:5]}\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è No se encontraron columnas de texto\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca5d64b2",
   "metadata": {},
   "source": [
    "## Revision y transformacion de los tipos de datos de cada columna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "85024c41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìã TIPOS DE DATOS DESPU√âS DE TRANSFORMACIONES:\n",
      "----------------------------------------\n",
      "merchant_id                   object\n",
      "_id                           object\n",
      "subsidiary                    object\n",
      "transaction_date      datetime64[ns]\n",
      "account_number                object\n",
      "user_id                       object\n",
      "transaction_amount           float64\n",
      "transaction_type            category\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "#Transformar columna transaction_date a tipo datetime\n",
    "df['transaction_date'] = pd.to_datetime(df['transaction_date'], errors='coerce')\n",
    "\n",
    "# Transformar columna transaction_amount a tipo num√©rico\n",
    "df['transaction_amount'] = pd.to_numeric(df['transaction_amount'], errors='coerce')\n",
    "\n",
    "#Transformar transaction_type a tipo categ√≥rico\n",
    "df['transaction_type'] = df['transaction_type'].astype('category')\n",
    "\n",
    "#Verificar nuevamente los tipos de datos\n",
    "print(\"\\nüìã TIPOS DE DATOS DESPU√âS DE TRANSFORMACIONES:\")\n",
    "print(\"-\" * 40)\n",
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12650bfe",
   "metadata": {},
   "source": [
    "## Verificar valores nulos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7147ee94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîç VERIFICANDO VALORES NULOS\n",
      "Total de columnas con valores nulos: 0\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nüîç VERIFICANDO VALORES NULOS\")\n",
    "\n",
    "nulos = df.isnull().sum()\n",
    "print(f\"Total de columnas con valores nulos: {nulos[nulos > 0].shape[0]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6c44153",
   "metadata": {},
   "source": [
    "## Verificar valores duplicados en IDs que deber√≠an ser √∫nicos (_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9ab1887",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîç VERIFICANDO VALORES DUPLICADOS EN IDs\n",
      "‚ö†Ô∏è Se encontraron 17 registros duplicados en la columna '_id'\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nüîç VERIFICANDO VALORES DUPLICADOS EN IDs\")\n",
    "\n",
    "duplicados = df['_id'].duplicated().sum()\n",
    "if duplicados > 0:\n",
    "    print(f\"‚ö†Ô∏è Se encontraron {duplicados} registros duplicados en la columna '_id'\")\n",
    "else:\n",
    "    print(\"‚úÖ No se encontraron registros duplicados en la columna '_id'\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "30c4e06e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total de registros en la columna '_id': 21516901\n",
      "IDs duplicados encontrados (0):\n",
      " []\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>merchant_id</th>\n",
       "      <th>_id</th>\n",
       "      <th>subsidiary</th>\n",
       "      <th>transaction_date</th>\n",
       "      <th>account_number</th>\n",
       "      <th>user_id</th>\n",
       "      <th>transaction_amount</th>\n",
       "      <th>transaction_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [merchant_id, _id, subsidiary, transaction_date, account_number, user_id, transaction_amount, transaction_type]\n",
       "Index: []"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Revisar los registros duplicados en '_id' manualmente\n",
    "\n",
    "# 0. Numero de registros totales en la columna '_id'\n",
    "total_ids = df['_id']\n",
    "print(f\"\\nTotal de registros en la columna '_id': {len(total_ids)}\")\n",
    "\n",
    "# 1. Obtener la lista de IDs que aparecen m√°s de una vez\n",
    "dup_ids = df.loc[df['_id'].duplicated(), '_id'].unique()\n",
    "print(f\"IDs duplicados encontrados ({len(dup_ids)}):\\n\", dup_ids)\n",
    "\n",
    "# 2. Filtrar todas las filas con esos IDs para inspecci√≥n\n",
    "df_dups = df[df['_id'].isin(dup_ids)].sort_values('_id')\n",
    "display(df_dups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "24af7c12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîÑ ELIMINANDO REGISTROS DUPLICADOS EN '_id'\n",
      "‚úÖ Duplicados de _id eliminados. Nuevo shape: (21516901, 8)\n",
      "Total de registros duplicados en '_id' despu√©s de limpieza: 0\n"
     ]
    }
   ],
   "source": [
    "# Despues de revisara a detalle No es un ‚Äúdoble pago‚Äù real, sino un retry o duplicaci√≥n en la capa de ingesti√≥n del banco.\n",
    "# Todas tienen la misma fecha y hora a excepci√≥n de una que tiene un segundo de diferencia.\n",
    "# Por lo tanto, podemos eliminarlas sin problema el primer registro de cada ID duplicado.\n",
    "print(\"\\nüîÑ ELIMINANDO REGISTROS DUPLICADOS EN '_id'\")\n",
    "\n",
    "df = df.drop_duplicates(subset=['_id'], keep='first').reset_index(drop=True)\n",
    "print(f\"‚úÖ Duplicados de _id eliminados. Nuevo shape: {df.shape}\")\n",
    "\n",
    "# Verificar nuevamente los valores duplicados\n",
    "duplicados = df['_id'].duplicated().sum()\n",
    "print(f\"Total de registros duplicados en '_id' despu√©s de limpieza: {duplicados}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43556617",
   "metadata": {},
   "source": [
    "## Valores fuera de rango o invalidos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "eacf6484",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ùå Montos ‚â§ 0: 0 filas\n"
     ]
    }
   ],
   "source": [
    "# 1. Montos <= 0\n",
    "mask_amount_non_positive = df['transaction_amount'] <= 0\n",
    "count_amount_non_positive = mask_amount_non_positive.sum()\n",
    "pct_amount_non_positive = count_amount_non_positive / len(df) * 100\n",
    "print(f\"‚ùå Montos ‚â§ 0: {count_amount_non_positive} filas\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d746b9e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÖ Fecha m√≠nima: 2021-01-01 00:00:40\n",
      "üìÖ Fecha m√°xima: 2021-11-30 23:59:49\n",
      "‚ùå Fechas fuera de [2021-01-01 00:00:40] / [2021-11-30 23:59:49]: 0 filas\n"
     ]
    }
   ],
   "source": [
    "# 2. Fechas fuera de rango\n",
    "\n",
    "fecha_min = df['transaction_date'].min()\n",
    "fecha_max = df['transaction_date'].max()\n",
    "print(f\"üìÖ Fecha m√≠nima: {fecha_min}\")\n",
    "print(f\"üìÖ Fecha m√°xima: {fecha_max}\")\n",
    "mask_date_before = df['transaction_date'] < fecha_min\n",
    "mask_date_after  = df['transaction_date'] > fecha_max\n",
    "count_date_bad = (mask_date_before | mask_date_after).sum()\n",
    "pct_date_bad = count_date_bad / len(df) * 100\n",
    "print(f\"‚ùå Fechas fuera de [{fecha_min}] / [{fecha_max}]: {count_date_bad} filas\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2007a21b",
   "metadata": {},
   "source": [
    "## IDs Inesperados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfe3df8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ùå _id con longitud ‚â† 32: 0 filas (0.0000 %)\n",
      "‚ùå _id con caracteres no hex: 0 filas (0.0000 %)\n",
      "‚ùå _id con espacios al inicio/final: 0 filas (0.0000 %)\n",
      "‚úÖ Espacios en _id recortados con .str.strip()\n"
     ]
    }
   ],
   "source": [
    "# 3. IDs inesperados\n",
    "# 4a) Longitud incorrecta (asumimos que debe ser 32 caracteres hex)\n",
    "mask_id_length = df['_id'].str.len() != 32\n",
    "count_id_length = mask_id_length.sum()\n",
    "pct_id_length = count_id_length / len(df) * 100\n",
    "print(f\"‚ùå _id con longitud ‚â† 32: {count_id_length} filas ({pct_id_length:.4f} %)\")\n",
    "\n",
    "# 4b) Caracteres no hexadecimales\n",
    "hex_pattern = re.compile(r'^[0-9a-fA-F]{32}$')\n",
    "mask_id_nonhex = ~df['_id'].str.match(hex_pattern)\n",
    "count_id_nonhex = mask_id_nonhex.sum()\n",
    "pct_id_nonhex = count_id_nonhex / len(df) * 100\n",
    "print(f\"‚ùå _id con caracteres no hex: {count_id_nonhex} filas ({pct_id_nonhex:.4f} %)\")\n",
    "\n",
    "# 4c) Espacios en blanco\n",
    "mask_id_whitespace = df['_id'].str.contains(r'^\\s|\\s$')\n",
    "count_id_whitespace = mask_id_whitespace.sum()\n",
    "pct_id_whitespace = count_id_whitespace / len(df) * 100\n",
    "print(f\"‚ùå _id con espacios al inicio/final: {count_id_whitespace} filas ({pct_id_whitespace:.4f} %)\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
